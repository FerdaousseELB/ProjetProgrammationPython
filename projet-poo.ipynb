{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b68d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886313dfae3f416aa41d2c9dab28990a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='corona', description='Subreddit:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91549df8f66b48d79ba35cd6b779a205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Reddit Limit:', max=500, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0fd81d3a8f4f049d6cb38d08948b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='corona', description='ArXiv Query Terms:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b430ade0a2451ab546fb1c626df5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='ArXiv Max Results:', max=500, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a6f6354f744a73aa37fe03e650553b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Collect and Display Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le fichier corpus_data.csv est crée avec 62 auteurs et 66 documents.\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from DataCollector import DataCollector\n",
    "from Author import Author\n",
    "from Document import Document\n",
    "from RedditDocument import RedditDocument\n",
    "from ArxivDocument import ArxivDocument\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def collect_data_and_display(subreddit, reddit_limit, arxiv_query_terms, arxiv_max_results):\n",
    "    # Créer une instance de DataCollector avec les paramètres fournis\n",
    "    collector = DataCollector(subreddit=subreddit_widget.value, limit=reddit_limit_widget.value,\n",
    "                          query_terms=arxiv_query_terms_widget.value.split(','), max_results=arxiv_max_results_widget.value)\n",
    "\n",
    "    # Collecter des données depuis Reddit\n",
    "    collector.collect_reddit_data()\n",
    "\n",
    "    # Collecter des données depuis ArXiv\n",
    "    #collector.collect_arxiv_data()\n",
    "       \n",
    "    collection = []\n",
    "    for nature, doc in collector.docs_bruts:\n",
    "        if nature == \"ArXiv\": \n",
    "            titre = doc[\"title\"].replace('\\n', '')  # On enlève les retours à la ligne\n",
    "            try:\n",
    "                authors = \", \".join([a[\"name\"] for a in doc[\"author\"]])  # On fait une liste d'auteurs, séparés par une virgule\n",
    "            except:\n",
    "                authors = doc[\"author\"][\"name\"]  # Si l'auteur est seul, pas besoin de liste\n",
    "            summary = doc[\"summary\"].replace(\"\\n\", \"\")  # On enlève les retours à la ligne\n",
    "            date = datetime.datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\")  # Formatage de la date en année/mois/jour avec librairie datetime\n",
    "\n",
    "            doc_classe = Document(titre, authors, date, doc[\"id\"], summary)  # Création du Document\n",
    "            collection.append(doc_classe)  # Ajout du Document à la liste.\n",
    "\n",
    "        elif nature == \"Reddit\":\n",
    "            titre = doc.title.replace(\"\\n\", '')\n",
    "            auteur = str(doc.author)\n",
    "            date = datetime.datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\")\n",
    "            url = str(doc.url)\n",
    "            texte = doc.selftext.replace(\"\\n\", \"\")\n",
    "            doc_classe = Document(titre, auteur, date, url, texte)\n",
    "            collection.append(doc_classe)\n",
    "    \n",
    "    authors = {}\n",
    "    aut2id = {}\n",
    "    num_auteurs_vus = 0\n",
    "    \n",
    "    for doc in collection:\n",
    "        if doc.auteur not in aut2id:\n",
    "            num_auteurs_vus += 1\n",
    "            authors[num_auteurs_vus] = Author(doc.auteur)\n",
    "            aut2id[doc.auteur] = num_auteurs_vus\n",
    "\n",
    "        authors[aut2id[doc.auteur]].add(doc.texte) \n",
    "    \n",
    "    corpus_data = {\n",
    "        'Titre': [],\n",
    "        'Auteur': [],\n",
    "        'Date': [],\n",
    "        'URL': [],\n",
    "        'Texte': []\n",
    "    }\n",
    "    \n",
    "    for doc in collection:\n",
    "        corpus_data['Titre'].append(doc.titre)\n",
    "        corpus_data['Auteur'].append(doc.auteur)\n",
    "        corpus_data['Date'].append(doc.date)\n",
    "        corpus_data['URL'].append(doc.url)\n",
    "        corpus_data['Texte'].append(doc.texte)\n",
    "        \n",
    "    corpus_df = pd.DataFrame(corpus_data)\n",
    "    corpus_df.to_csv('corpus_data.csv', sep='\\t', index=False)\n",
    "    \n",
    "    message = \"le fichier corpus_data.csv est crée avec {} auteurs et {} documents.\"\n",
    "    print(message.format(len(authors), len(collection)))\n",
    "\n",
    "# Créer les widgets pour le formulaire\n",
    "subreddit_widget = widgets.Text(value='corona', description='Subreddit:')\n",
    "reddit_limit_widget = widgets.IntSlider(value=100, min=1, max=500, step=1, description='Reddit Limit:')\n",
    "arxiv_query_terms_widget = widgets.Text(value='corona', description='ArXiv Query Terms:')\n",
    "arxiv_max_results_widget = widgets.IntSlider(value=100, min=1, max=500, step=1, description='ArXiv Max Results:')\n",
    "\n",
    "# Créer le bouton pour déclencher la collecte de données\n",
    "button = widgets.Button(description='Collect and Display Data')\n",
    "\n",
    "# Définir la fonction à exécuter lors du clic sur le bouton\n",
    "def on_button_click(b):\n",
    "    collect_data_and_display(subreddit_widget.value, reddit_limit_widget.value,\n",
    "                              arxiv_query_terms_widget.value.split(','), arxiv_max_results_widget.value)\n",
    "\n",
    "# Associer la fonction au clic sur le bouton\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Afficher les widgets\n",
    "display(subreddit_widget, reddit_limit_widget, arxiv_query_terms_widget, arxiv_max_results_widget, button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f50088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "####################################\n",
      "####################################\n",
      "####################################\n",
      "Occurrences trouvées pour le mot-clé 'article':\n",
      "article\n",
      "Article\n",
      "####################################\n",
      "####################################\n",
      "           Contexte Gauche Motif Trouvé           Contexte Droit\n",
      "0   ...using built. I read      article    below. Does anyone...\n",
      "1  ...ppreciated! Thanks![      Article  ](https://www.presse...\n",
      "####################################\n",
      "####################################\n",
      "####################################\n",
      "####################################\n",
      "Vocabulaire construit :\n",
      "goodwill\n",
      "definitely\n",
      "spread\n",
      "w\n",
      "excellent\n",
      "blackout\n",
      "rescue\n",
      "cinco\n",
      "isolated\n",
      "interesting\n",
      "engine\n",
      "lincoln\n",
      "gov\n",
      "input\n",
      "gossip\n",
      "micamente\n",
      "within\n",
      "some\n",
      "know\n",
      "greatly\n",
      "anybody\n",
      "to\n",
      "saw\n",
      "histories\n",
      "help\n",
      "coughing\n",
      "grocery\n",
      "loud\n",
      "around\n",
      "ideas\n",
      "feel\n",
      "law\n",
      "morning\n",
      "disponible\n",
      "hearing\n",
      "flying\n",
      "every\n",
      "going\n",
      "rd\n",
      "keeper\n",
      "older\n",
      "sacred\n",
      "most\n",
      "install\n",
      "perd\n",
      "buying\n",
      "department\n",
      "rxki\n",
      "inn\n",
      "project\n",
      "best\n",
      "specific\n",
      "mainly\n",
      "last\n",
      "pasar\n",
      "since\n",
      "carpooling\n",
      "slightly\n",
      "anaheim\n",
      "legs\n",
      "comment\n",
      "feels\n",
      "grad\n",
      "ze\n",
      "describe\n",
      "adults\n",
      "her\n",
      "individuals\n",
      "bodybuilding\n",
      "put\n",
      "con\n",
      "typically\n",
      "mikeultra\n",
      "luck\n",
      "accountability\n",
      "t\n",
      "cars\n",
      "outbreak\n",
      "hang\n",
      "journey\n",
      "traffic\n",
      "chavez\n",
      "midnight\n",
      "recipe\n",
      "bikes\n",
      "mall\n",
      "ensure\n",
      "passion\n",
      "shallow\n",
      "national\n",
      "sucked\n",
      "aware\n",
      "said\n",
      "plan\n",
      "shot\n",
      "oggy\n",
      "pains\n",
      "cleanliness\n",
      "dm\n",
      "neurodivergent\n",
      "than\n",
      "house\n",
      "when\n",
      "green\n",
      "came\n",
      "save\n",
      "round\n",
      "got\n",
      "posibilidades\n",
      "aren\n",
      "otros\n",
      "lol\n",
      "car\n",
      "culture\n",
      "maps\n",
      "second\n",
      "locally\n",
      "husband\n",
      "filipinos\n",
      "reason\n",
      "options\n",
      "level\n",
      "should\n",
      "video\n",
      "think\n",
      "selling\n",
      "ebikes\n",
      "concerned\n",
      "minutes\n",
      "exit\n",
      "halfway\n",
      "additional\n",
      "kiwimanzuka\n",
      "bro\n",
      "shop\n",
      "gathering\n",
      "beach\n",
      "clean\n",
      "past\n",
      "may\n",
      "seeing\n",
      "econ\n",
      "been\n",
      "everything\n",
      "community\n",
      "empire\n",
      "socal\n",
      "word\n",
      "donate\n",
      "similar\n",
      "diff\n",
      "become\n",
      "first\n",
      "helicopters\n",
      "undefeated\n",
      "resemblance\n",
      "years\n",
      "sensible\n",
      "jamenabar\n",
      "chunks\n",
      "scares\n",
      "r\n",
      "am\n",
      "safe\n",
      "via\n",
      "sane\n",
      "australian\n",
      "lambinater\n",
      "everyone\n",
      "lgbtq\n",
      "near\n",
      "making\n",
      "minded\n",
      "las\n",
      "crossroads\n",
      "thoughts\n",
      "attend\n",
      "life\n",
      "little\n",
      "coronaca\n",
      "freeway\n",
      "why\n",
      "top\n",
      "killing\n",
      "long\n",
      "moments\n",
      "strip\n",
      "ve\n",
      "wildfires\n",
      "reaching\n",
      "centennial\n",
      "time\n",
      "middle\n",
      "circle\n",
      "formation\n",
      "posted\n",
      "college\n",
      "two\n",
      "wants\n",
      "used\n",
      "not\n",
      "outside\n",
      "kinda\n",
      "during\n",
      "also\n",
      "context\n",
      "only\n",
      "prices\n",
      "nothing\n",
      "would\n",
      "ceasar\n",
      "foot\n",
      "hs\n",
      "main\n",
      "kindle\n",
      "relevant\n",
      "room\n",
      "markets\n",
      "least\n",
      "la\n",
      "routes\n",
      "way\n",
      "u\n",
      "day\n",
      "female\n",
      "white\n",
      "suggestions\n",
      "amigos\n",
      "cambi\n",
      "as\n",
      "remember\n",
      "what\n",
      "question\n",
      "security\n",
      "dinner\n",
      "real\n",
      "sex\n",
      "deemed\n",
      "www\n",
      "muy\n",
      "recently\n",
      "live\n",
      "temor\n",
      "today\n",
      "curse\n",
      "actually\n",
      "rimpau\n",
      "problematic\n",
      "elementary\n",
      "para\n",
      "curious\n",
      "f\n",
      "n\n",
      "pick\n",
      "target\n",
      "wonder\n",
      "across\n",
      "start\n",
      "dark\n",
      "all\n",
      "read\n",
      "workers\n",
      "contain\n",
      "southern\n",
      "bee\n",
      "yelp\n",
      "lodge\n",
      "respaldo\n",
      "safety\n",
      "gift\n",
      "currently\n",
      "enjoy\n",
      "proof\n",
      "com\n",
      "things\n",
      "love\n",
      "down\n",
      "mission\n",
      "land\n",
      "inesperadamente\n",
      "store\n",
      "cultura\n",
      "half\n",
      "ciudad\n",
      "towards\n",
      "on\n",
      "cal\n",
      "over\n",
      "martoutedit\n",
      "look\n",
      "matter\n",
      "fucked\n",
      "minority\n",
      "really\n",
      "nearby\n",
      "power\n",
      "bit\n",
      "lemon\n",
      "find\n",
      "dealing\n",
      "property\n",
      "battery\n",
      "weirdos\n",
      "already\n",
      "wondering\n",
      "who\n",
      "you\n",
      "forward\n",
      "vicinity\n",
      "https\n",
      "prior\n",
      "burial\n",
      "gym\n",
      "amateur\n",
      "try\n",
      "couple\n",
      "but\n",
      "approved\n",
      "incredible\n",
      "implies\n",
      "details\n",
      "number\n",
      "that\n",
      "ingl\n",
      "push\n",
      "welcoming\n",
      "elder\n",
      "comments\n",
      "tomorrow\n",
      "appropriate\n",
      "disabled\n",
      "stovetop\n",
      "collar\n",
      "ll\n",
      "ok\n",
      "snakes\n",
      "activity\n",
      "though\n",
      "promedio\n",
      "contact\n",
      "hesitate\n",
      "hill\n",
      "fast\n",
      "restaurant\n",
      "tore\n",
      "dont\n",
      "todo\n",
      "reflect\n",
      "notice\n",
      "kalaveras\n",
      "escape\n",
      "state\n",
      "up\n",
      "friend\n",
      "insights\n",
      "looked\n",
      "changed\n",
      "dating\n",
      "xlp\n",
      "saying\n",
      "shares\n",
      "fantastic\n",
      "someone\n",
      "por\n",
      "google\n",
      "learn\n",
      "likely\n",
      "looking\n",
      "their\n",
      "mi\n",
      "areas\n",
      "far\n",
      "values\n",
      "ready\n",
      "estudio\n",
      "theres\n",
      "grant\n",
      "guy\n",
      "either\n",
      "made\n",
      "don\n",
      "ig\n",
      "swarm\n",
      "utilities\n",
      "seem\n",
      "hit\n",
      "thhda\n",
      "hilly\n",
      "many\n",
      "an\n",
      "provide\n",
      "vivir\n",
      "working\n",
      "haven\n",
      "well\n",
      "call\n",
      "cerrito\n",
      "center\n",
      "seat\n",
      "irvine\n",
      "blanket\n",
      "website\n",
      "about\n",
      "emigrar\n",
      "remove\n",
      "conocer\n",
      "bw\n",
      "check\n",
      "track\n",
      "nervous\n",
      "x\n",
      "participation\n",
      "here\n",
      "away\n",
      "pass\n",
      "dos\n",
      "de\n",
      "times\n",
      "boards\n",
      "trabuco\n",
      "recreation\n",
      "grinding\n",
      "opinions\n",
      "trip\n",
      "goals\n",
      "articles\n",
      "else\n",
      "terramor\n",
      "mbito\n",
      "motivation\n",
      "particular\n",
      "shepherd\n",
      "legalmente\n",
      "crab\n",
      "always\n",
      "advance\n",
      "comedian\n",
      "discussion\n",
      "called\n",
      "hotel\n",
      "warm\n",
      "el\n",
      "folks\n",
      "sidebar\n",
      "voted\n",
      "owner\n",
      "everytime\n",
      "politicians\n",
      "safer\n",
      "nights\n",
      "sauce\n",
      "guest\n",
      "ask\n",
      "the\n",
      "major\n",
      "area\n",
      "hasta\n",
      "mylefthandkilledme\n",
      "buffet\n",
      "anywhere\n",
      "minted\n",
      "bs\n",
      "active\n",
      "splurge\n",
      "from\n",
      "escolar\n",
      "average\n",
      "interested\n",
      "pfq\n",
      "post\n",
      "cool\n",
      "missing\n",
      "asian\n",
      "told\n",
      "west\n",
      "experiences\n",
      "had\n",
      "thank\n",
      "left\n",
      "country\n",
      "blue\n",
      "might\n",
      "bunch\n",
      "off\n",
      "this\n",
      "police\n",
      "reach\n",
      "blvd\n",
      "randomly\n",
      "suggesting\n",
      "tag\n",
      "race\n",
      "backyard\n",
      "coronavirus\n",
      "delightful\n",
      "focused\n",
      "os\n",
      "foundations\n",
      "removal\n",
      "coronians\n",
      "river\n",
      "shoot\n",
      "belongings\n",
      "smash\n",
      "abt\n",
      "clear\n",
      "seemingly\n",
      "apps\n",
      "grand\n",
      "comparatively\n",
      "zona\n",
      "locations\n",
      "traveling\n",
      "afternoon\n",
      "approximately\n",
      "mayor\n",
      "gave\n",
      "workout\n",
      "irrelevant\n",
      "kindergarten\n",
      "guys\n",
      "yrxkax\n",
      "m\n",
      "side\n",
      "make\n",
      "message\n",
      "appreciated\n",
      "estudiando\n",
      "keepers\n",
      "mail\n",
      "parts\n",
      "red\n",
      "noise\n",
      "absolutely\n",
      "week\n",
      "lookout\n",
      "letter\n",
      "spam\n",
      "person\n",
      "care\n",
      "residents\n",
      "roommate\n",
      "hay\n",
      "millennials\n",
      "costs\n",
      "are\n",
      "mole\n",
      "one\n",
      "brian\n",
      "relatives\n",
      "speaking\n",
      "following\n",
      "sister\n",
      "school\n",
      "event\n",
      "avenida\n",
      "completely\n",
      "affordable\n",
      "mixed\n",
      "test\n",
      "consultas\n",
      "nearly\n",
      "corrections\n",
      "flavorful\n",
      "lost\n",
      "county\n",
      "very\n",
      "bound\n",
      "intense\n",
      "entiendo\n",
      "article\n",
      "pap\n",
      "ni\n",
      "connect\n",
      "so\n",
      "q\n",
      "california\n",
      "worth\n",
      "family\n",
      "activa\n",
      "o\n",
      "commuting\n",
      "totally\n",
      "estoy\n",
      "miles\n",
      "metrolink\n",
      "meetup\n",
      "known\n",
      "link\n",
      "name\n",
      "local\n",
      "head\n",
      "relatively\n",
      "spring\n",
      "pretty\n",
      "limits\n",
      "however\n",
      "waterspout\n",
      "lculos\n",
      "adds\n",
      "liked\n",
      "cajalco\n",
      "missouri\n",
      "started\n",
      "agenda\n",
      "cringe\n",
      "be\n",
      "kinnda\n",
      "ages\n",
      "hiring\n",
      "biy\n",
      "card\n",
      "tea\n",
      "have\n",
      "toll\n",
      "whenever\n",
      "los\n",
      "equipment\n",
      "cop\n",
      "can\n",
      "them\n",
      "big\n",
      "expect\n",
      "mountains\n",
      "just\n",
      "moving\n",
      "needs\n",
      "non\n",
      "sure\n",
      "they\n",
      "ese\n",
      "ayres\n",
      "esa\n",
      "ton\n",
      "painting\n",
      "into\n",
      "my\n",
      "running\n",
      "whole\n",
      "direction\n",
      "finding\n",
      "now\n",
      "bears\n",
      "treatment\n",
      "willing\n",
      "type\n",
      "therapy\n",
      "lore\n",
      "curb\n",
      "if\n",
      "saves\n",
      "townhouse\n",
      "ways\n",
      "autistic\n",
      "for\n",
      "quesadillas\n",
      "yet\n",
      "sounding\n",
      "spots\n",
      "meet\n",
      "starts\n",
      "opening\n",
      "ownership\n",
      "loving\n",
      "crazy\n",
      "temecula\n",
      "meets\n",
      "oc\n",
      "full\n",
      "recap\n",
      "getting\n",
      "photos\n",
      "advice\n",
      "adaptaci\n",
      "tengo\n",
      "sheltered\n",
      "boom\n",
      "invitation\n",
      "a\n",
      "did\n",
      "cookie\n",
      "like\n",
      "hello\n",
      "allowed\n",
      "eastvale\n",
      "recommendations\n",
      "tornado\n",
      "simple\n",
      "fire\n",
      "thinking\n",
      "isn\n",
      "seg\n",
      "s\n",
      "received\n",
      "site\n",
      "no\n",
      "scared\n",
      "driving\n",
      "thanks\n",
      "topic\n",
      "bot\n",
      "any\n",
      "activos\n",
      "honestly\n",
      "much\n",
      "ago\n",
      "throat\n",
      "after\n",
      "hiking\n",
      "endangered\n",
      "of\n",
      "alarms\n",
      "which\n",
      "wired\n",
      "stay\n",
      "st\n",
      "more\n",
      "new\n",
      "because\n",
      "updates\n",
      "having\n",
      "ca\n",
      "inmigrante\n",
      "tracks\n",
      "aunque\n",
      "miraloma\n",
      "work\n",
      "board\n",
      "let\n",
      "money\n",
      "replicate\n",
      "salon\n",
      "history\n",
      "clumped\n",
      "miguel\n",
      "related\n",
      "found\n",
      "nead\n",
      "back\n",
      "were\n",
      "hijo\n",
      "allows\n",
      "home\n",
      "happen\n",
      "box\n",
      "places\n",
      "get\n",
      "trying\n",
      "ingresos\n",
      "pfizer\n",
      "preferably\n",
      "seems\n",
      "hoarse\n",
      "buscando\n",
      "another\n",
      "will\n",
      "easily\n",
      "other\n",
      "pm\n",
      "resident\n",
      "norco\n",
      "between\n",
      "bueno\n",
      "redshores\n",
      "discussing\n",
      "arco\n",
      "move\n",
      "game\n",
      "shopping\n",
      "vp\n",
      "makes\n",
      "want\n",
      "radius\n",
      "somewhere\n",
      "lax\n",
      "please\n",
      "reddit\n",
      "neighbor\n",
      "recent\n",
      "male\n",
      "llevar\n",
      "cleaning\n",
      "breaks\n",
      "tree\n",
      "risk\n",
      "showed\n",
      "protest\n",
      "noted\n",
      "deer\n",
      "daughters\n",
      "your\n",
      "congested\n",
      "searching\n",
      "neither\n",
      "heard\n",
      "information\n",
      "sigh\n",
      "how\n",
      "re\n",
      "riverside\n",
      "mins\n",
      "eqfj\n",
      "city\n",
      "parking\n",
      "windows\n",
      "horny\n",
      "skyline\n",
      "months\n",
      "mods\n",
      "medios\n",
      "in\n",
      "mountain\n",
      "precios\n",
      "liquor\n",
      "disappeared\n",
      "below\n",
      "different\n",
      "meeting\n",
      "tips\n",
      "by\n",
      "under\n",
      "body\n",
      "is\n",
      "ground\n",
      "couch\n",
      "our\n",
      "coming\n",
      "those\n",
      "debating\n",
      "considerando\n",
      "hardcore\n",
      "inspire\n",
      "where\n",
      "le\n",
      "rio\n",
      "process\n",
      "grew\n",
      "girlfriend\n",
      "harassed\n",
      "gf\n",
      "condo\n",
      "salvation\n",
      "commute\n",
      "quiet\n",
      "proceso\n",
      "better\n",
      "mexican\n",
      "westminster\n",
      "go\n",
      "million\n",
      "ie\n",
      "events\n",
      "fan\n",
      "part\n",
      "apartment\n",
      "see\n",
      "workouts\n",
      "end\n",
      "she\n",
      "latina\n",
      "hice\n",
      "interracial\n",
      "town\n",
      "quite\n",
      "priced\n",
      "slows\n",
      "plans\n",
      "travel\n",
      "canyon\n",
      "tried\n",
      "inland\n",
      "worry\n",
      "story\n",
      "wanna\n",
      "aunt\n",
      "kettle\n",
      "kids\n",
      "free\n",
      "enchilada\n",
      "nails\n",
      "lowkey\n",
      "seriamente\n",
      "comunidad\n",
      "was\n",
      "black\n",
      "valentines\n",
      "lot\n",
      "subject\n",
      "removed\n",
      "hear\n",
      "closest\n",
      "bulletin\n",
      "mucho\n",
      "looks\n",
      "deadly\n",
      "esto\n",
      "its\n",
      "effort\n",
      "reduce\n",
      "progress\n",
      "these\n",
      "im\n",
      "chino\n",
      "rs\n",
      "posts\n",
      "mile\n",
      "year\n",
      "strong\n",
      "housemate\n",
      "road\n",
      "failed\n",
      "special\n",
      "dura\n",
      "frontage\n",
      "bank\n",
      "groomed\n",
      "newly\n",
      "weeks\n",
      "weather\n",
      "error\n",
      "mixers\n",
      "beer\n",
      "hills\n",
      "place\n",
      "excited\n",
      "weekend\n",
      "must\n",
      "army\n",
      "building\n",
      "soccer\n",
      "etc\n",
      "same\n",
      "beautiful\n",
      "rent\n",
      "lights\n",
      "too\n",
      "avoid\n",
      "chest\n",
      "bad\n",
      "believe\n",
      "development\n",
      "viviendo\n",
      "starbucks\n",
      "pushing\n",
      "sick\n",
      "corona\n",
      "heads\n",
      "vaccine\n",
      "being\n",
      "considering\n",
      "lagos\n",
      "people\n",
      "before\n",
      "park\n",
      "drawn\n",
      "cameras\n",
      "good\n",
      "nearest\n",
      "mezclando\n",
      "apple\n",
      "bees\n",
      "couldn\n",
      "job\n",
      "covid\n",
      "something\n",
      "fitness\n",
      "views\n",
      "geared\n",
      "mistake\n",
      "there\n",
      "while\n",
      "quisiera\n",
      "vons\n",
      "education\n",
      "possibly\n",
      "hey\n",
      "gran\n",
      "taken\n",
      "nivel\n",
      "vista\n",
      "caused\n",
      "wandering\n",
      "inside\n",
      "centers\n",
      "sore\n",
      "ideal\n",
      "comercial\n",
      "headlines\n",
      "i\n",
      "memorable\n",
      "tinted\n",
      "user\n",
      "discuss\n",
      "valley\n",
      "could\n",
      "news\n",
      "posting\n",
      "info\n",
      "watched\n",
      "station\n",
      "xqt\n",
      "amazing\n",
      "del\n",
      "chipotle\n",
      "pero\n",
      "coughs\n",
      "does\n",
      "updated\n",
      "flu\n",
      "sideways\n",
      "recientemente\n",
      "me\n",
      "y\n",
      "dog\n",
      "social\n",
      "ratings\n",
      "business\n",
      "en\n",
      "women\n",
      "windshield\n",
      "subreddit\n",
      "experience\n",
      "responsible\n",
      "mis\n",
      "vilification\n",
      "support\n",
      "has\n",
      "trafffic\n",
      "jazzersize\n",
      "es\n",
      "with\n",
      "huge\n",
      "drive\n",
      "age\n",
      "temescal\n",
      "built\n",
      "apologize\n",
      "un\n",
      "housing\n",
      "additionally\n",
      "anyone\n",
      "passenger\n",
      "open\n",
      "complete\n",
      "prosperar\n",
      "keep\n",
      "taking\n",
      "jokes\n",
      "pandemic\n",
      "and\n",
      "partner\n",
      "each\n",
      "shit\n",
      "right\n",
      "us\n",
      "went\n",
      "former\n",
      "team\n",
      "through\n",
      "line\n",
      "elderly\n",
      "friends\n",
      "preocupo\n",
      "costo\n",
      "at\n",
      "hopefully\n",
      "it\n",
      "path\n",
      "helpful\n",
      "dirty\n",
      "even\n",
      "grande\n",
      "boomers\n",
      "route\n",
      "together\n",
      "pressenterprise\n",
      "maybe\n",
      "alquileres\n",
      "great\n",
      "old\n",
      "members\n",
      "do\n",
      "sexually\n",
      "otra\n",
      "racism\n",
      "barrera\n",
      "shouldn\n",
      "edit\n",
      "shots\n",
      "take\n",
      "restaurants\n",
      "users\n",
      "tustin\n",
      "receptiva\n",
      "una\n",
      "moved\n",
      "soon\n",
      "anything\n",
      "hoozay\n",
      "jr\n",
      "hell\n",
      "orange\n",
      "spreading\n",
      "ontario\n",
      "out\n",
      "friendly\n",
      "buy\n",
      "we\n",
      "rather\n",
      "claim\n",
      "or\n",
      "services\n",
      "cough\n",
      "seafood\n",
      "notify\n",
      "homeless\n",
      "leads\n",
      "virus\n",
      "yes\n",
      "south\n",
      "pisses\n",
      "c\n",
      "train\n",
      "public\n",
      "tonight\n",
      "took\n",
      "splitting\n",
      "until\n",
      "mejor\n",
      "mini\n",
      "clothes\n",
      "exist\n",
      "recommend\n",
      "imma\n",
      "personally\n",
      "longtime\n",
      "tell\n",
      "close\n",
      "doing\n",
      "liquidar\n",
      "cheesemakingmom\n",
      "elections\n",
      "super\n",
      "smoker\n",
      "occupied\n",
      "thing\n",
      "vida\n",
      "gen\n",
      "informaci\n",
      "such\n",
      "hope\n",
      "general\n",
      "vacation\n",
      "four\n",
      "squeezed\n",
      "e\n",
      "food\n",
      "lady\n",
      "puntos\n",
      "hi\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "from Corpus import Corpus\n",
    "\n",
    "# Charger le DataFrame à partir du fichier CSV\n",
    "loaded_corpus_df = pd.read_csv('corpus_data.csv', sep='\\t')\n",
    "\n",
    "# Convertir le DataFrame en Corpus\n",
    "loaded_corpus = Corpus(\"Mon corpus chargé\")\n",
    "\n",
    "for index, row in loaded_corpus_df.iterrows():\n",
    "    doc = Document(\n",
    "        titre=row['Titre'],\n",
    "        auteur=row['Auteur'],\n",
    "        date=row['Date'],\n",
    "        url=row['URL'],\n",
    "        texte=row['Texte']\n",
    "    )\n",
    "    loaded_corpus.add(doc)  \n",
    "\n",
    "# Afficher le Corpus chargé\n",
    "#print(loaded_corpus)\n",
    "print('####################################')\n",
    "print('####################################')\n",
    "#loaded_corpus.show(tri=\"123\")\n",
    "print('####################################')\n",
    "print('####################################')\n",
    "loaded_corpus.search(\"article\")\n",
    "print('####################################')\n",
    "print('####################################')\n",
    "loaded_corpus.concorde(\"article\")\n",
    "print('####################################')\n",
    "print('####################################')\n",
    "#loaded_corpus.stats(top_n_words=15)\n",
    "print('####################################')\n",
    "print('####################################')\n",
    "loaded_corpus.afficher_vocabulaire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327d038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
